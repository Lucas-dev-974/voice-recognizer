{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 64)          64000     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               98816     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164106 (641.04 KB)\n",
      "Trainable params: 164106 (641.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def model(learning_rate):\n",
    "    model = tf.keras.Sequential()\n",
    "    # Add an Embedding layer expecting input vocab of size 1000, and\n",
    "    # output embedding dimension of size 64.\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "    # Add a LSTM layer with 128 internal units.\n",
    "    model.add(tf.keras.layers.LSTM(128))\n",
    "\n",
    "    # Add a Dense layer with 10 units.\n",
    "    model.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_ = model(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe shape: (841, 56)\n",
      "label shape: (841, 1)\n",
      "label:                                                  label\n",
      "0    04383b5618f4d8d8ef2b075c6e24f754ac6c0795717058...\n",
      "1    04383b5618f4d8d8ef2b075c6e24f754ac6c0795717058...\n",
      "2    04383b5618f4d8d8ef2b075c6e24f754ac6c0795717058...\n",
      "3    04383b5618f4d8d8ef2b075c6e24f754ac6c0795717058...\n",
      "4    04383b5618f4d8d8ef2b075c6e24f754ac6c0795717058...\n",
      "..                                                 ...\n",
      "836  29fd4e95ceaa32e201f4ec1c2ac5ad2b978b8661450272...\n",
      "837  29fd4e95ceaa32e201f4ec1c2ac5ad2b978b8661450272...\n",
      "838  29fd4e95ceaa32e201f4ec1c2ac5ad2b978b8661450272...\n",
      "839  29fd4e95ceaa32e201f4ec1c2ac5ad2b978b8661450272...\n",
      "840  29fd4e95ceaa32e201f4ec1c2ac5ad2b978b8661450272...\n",
      "\n",
      "[841 rows x 1 columns]\n",
      "df shape (841, 55)\n",
      "df cols: Index(['chroma_stft_mean', 'chroma_stft_var', 'rms_mean', 'rms_var',\n",
      "       'spectral_centroid_mean', 'spectral_centroid_var',\n",
      "       'spectral_bandwidth_mean', 'spectral_bandwidth_var', 'rolloff_mean',\n",
      "       'rolloff_var', 'zero_crossing_rate_mean', 'zero_crossing_rate_var',\n",
      "       'harmony_mean', 'harmony_var', 'tempo', 'mfcc1_mean', 'mfcc1_var',\n",
      "       'mfcc2_mean', 'mfcc2_var', 'mfcc3_mean', 'mfcc3_var', 'mfcc4_mean',\n",
      "       'mfcc4_var', 'mfcc5_mean', 'mfcc5_var', 'mfcc6_mean', 'mfcc6_var',\n",
      "       'mfcc7_mean', 'mfcc7_var', 'mfcc8_mean', 'mfcc8_var', 'mfcc9_mean',\n",
      "       'mfcc9_var', 'mfcc10_mean', 'mfcc10_var', 'mfcc11_mean', 'mfcc11_var',\n",
      "       'mfcc12_mean', 'mfcc12_var', 'mfcc13_mean', 'mfcc13_var', 'mfcc14_mean',\n",
      "       'mfcc14_var', 'mfcc15_mean', 'mfcc15_var', 'mfcc16_mean', 'mfcc16_var',\n",
      "       'mfcc17_mean', 'mfcc17_var', 'mfcc18_mean', 'mfcc18_var', 'mfcc19_mean',\n",
      "       'mfcc19_var', 'mfcc20_mean', 'mfcc20_var'],\n",
      "      dtype='object')\n",
      "trainset:                                                  label\n",
      "730  1e848413a3350d126cf0ce308fdae55242765ba6161db0...\n",
      "500  1653ff7efc02d8f0e0d8be05adb19e1bfca543cee27730...\n",
      "775  29fd4e95ceaa32e201f4ec1c2ac5ad2b978b8661450272...\n",
      "109  049331a0346569d9b41738e0f31f495d097afc16eb54ef...\n",
      "72   04383b5618f4d8d8ef2b075c6e24f754ac6c0795717058...\n",
      "..                                                 ...\n",
      "71   04383b5618f4d8d8ef2b075c6e24f754ac6c0795717058...\n",
      "106  049331a0346569d9b41738e0f31f495d097afc16eb54ef...\n",
      "270  05dcd675ff28c44de2d0bd7030c78fb36acf063b2c4637...\n",
      "435  132887d56b0a8a5fc31dda4427b695133e69d6748b6602...\n",
      "102  049331a0346569d9b41738e0f31f495d097afc16eb54ef...\n",
      "\n",
      "[756 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./librosa_processed_features.csv\")\n",
    "print(\"dataframe shape:\", df.shape)\n",
    "\n",
    "labels = {\"label\": df[\"label\"]}\n",
    "labels = pd.DataFrame(labels)\n",
    "\n",
    "df.drop(\"label\", axis=1)\n",
    "df.pop(\"label\")\n",
    "\n",
    "labels.columns \n",
    "print(\"label shape:\", labels.shape)\n",
    "print(\"label:\", labels)\n",
    "\n",
    "print(\"df shape\", df.shape)\n",
    "print(\"df cols:\", df.columns)\n",
    "\n",
    "# Diviser l'ensemble d'entraînement en ensemble d'entraînement et ensemble de validation\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    df,\n",
    "    labels,\n",
    "    test_size=0.1,  # ajustez la taille de l'ensemble de validation selon vos besoins\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"trainset:\", train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(756, 55) (756, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_data\u001b[38;5;241m.\u001b[39mshape, train_labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file61x5xxfy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/lucas/PersonalDEV/voice-recognizer/.venv/lib/python3.11/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "print(train_data.shape, train_labels.shape)\n",
    "\n",
    "model_.fit(train_data, train_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
